# Default values for Chipster Helm chart
# This is a YAML-formatted file.
# Declare variables to be passed into the templates.

# deployments defines all Chipster services
# generate-passwords.bash will generate all deployments.*.password fields
deployments:
  # keys written in camelCase to make them easier to use in templates
  webServer:
    # name is the Chipster service name in its usual dash-separated form
    name: web-server
    # class to start if using chipster-web-server image
    class: ""
    # image is the name of the container image
    image: web-server
    # apiPort is the port which the process binds to serve API requests
    apiPort: 8000
    # adminPort is the port which the process binds to serve admin requests
    adminPort: 8100
    # eventsPort is the port which the process binds to serve WebSocket connections
    eventsPort: ""
    # workDir is the working directory in container where the process is started
    workDir: /opt/chipster
    # password is used by a Chipster service to authenticate to the auth service
    password: ""
    # configs is a YAML map to pass configuration key-value pairs to the Chipster service
    configs: {}
    # useDefaultImageRepo decides whether image value above should be prefixed with a value of images.chipsterImageRepo
    useDefaultImageRepo: true
    # replicas is the number of containers that run this service
    replicas: ""
    # enableAdminRoute decides whether an IngressRoute is created for the admin port/service, allowing requests from outside of the K3s. Set to "default", "enable" or "disable".
    adminRoute: "default"
  auth:
    name: auth
    class: fi.csc.chipster.auth.AuthenticationService
    image: chipster-web-server
    apiPort: 8002
    adminPort: 8102
    eventsPort: ""
    workDir: /opt/chipster
    password: ""
    configs:
      # db-fallback disables the use of an embedded H2 database if connection to Postgres fails
    db-fallback: false
    useDefaultImageRepo: true
    replicas: ""
    adminRoute: "default"
  serviceLocator:
    name: service-locator
    class: fi.csc.chipster.servicelocator.ServiceLocator
    image: chipster-web-server
    apiPort: 8003
    adminPort: 8103
    eventsPort: ""
    workDir: /opt/chipster
    password: ""
    configs: {}
    useDefaultImageRepo: true
    replicas: ""
    adminRoute: "default"
  sessionDb:
    name: session-db
    class: fi.csc.chipster.sessiondb.SessionDb
    image: chipster-web-server
    apiPort: 8004
    adminPort: 8104
    eventsPort: 8005
    workDir: /opt/chipster
    password: ""
    configs: 
    # db-fallback disables the use of an embedded H2 database if connection to Postgres fails
    db-fallback: false
    useDefaultImageRepo: true
    replicas: ""
    adminRoute: "default"
  scheduler:
    name: scheduler
    class: fi.csc.chipster.scheduler.Scheduler
    image: chipster-web-server
    apiPort: 8006
    adminPort: 8106
    eventsPort: ""
    workDir: /opt/chipster
    password: ""
    configs: {}
    useDefaultImageRepo: true
    replicas: ""
    adminRoute: "default"
  fileBroker:
    name: file-broker
    class: fi.csc.chipster.filebroker.FileBroker
    image: chipster-web-server
    apiPort: 8007
    adminPort: 8107
    eventsPort: ""
    workDir: /opt/chipster
    password: ""
    configs: {}
    useDefaultImageRepo: true
    replicas: ""
    adminRoute: "default"
  fileStorage:
    name: file-storage
    class: fi.csc.chipster.filestorage.FileStorage
    image: chipster-web-server
    apiPort: 8016
    adminPort: 8116
    eventsPort: ""
    workDir: /opt/chipster
    password: ""
    # storageVolumeSize is the maximum total size of users' files (although K3s Local Storage Provider probably doesn't enforce it)
    storageVolumeSize: 300Gi
    configs: {}
    useDefaultImageRepo: true
    replicas: ""
    adminRoute: "default"
  toolbox:
    name: toolbox
    class: ""
    image: toolbox
    apiPort: 8008
    adminPort: 8108    
    eventsPort: ""
    # workDir of toolbox is different, because of the clash of /opt/chipster/tools (tools-bin) and toolbox/tools (tool scripts) directories
    workDir: /opt/chipster/toolbox
    password: ""
    configs: {}
    useDefaultImageRepo: true
    replicas: ""
    adminRoute: "default"
  sessionWorker:
    name: session-worker
    class: fi.csc.chipster.sessionworker.SessionWorker
    image: chipster-web-server
    apiPort: 8009
    adminPort: 8109
    eventsPort: ""
    workDir: /opt/chipster
    password: ""
    configs: {}
    useDefaultImageRepo: true
    replicas: ""
    adminRoute: "default"
  typeService:
    name: type-service
    class: ""
    image: chipster-web-server-js
    apiPort: 8010
    adminPort: 8110
    eventsPort: ""
    workDir: /opt/chipster
    password: ""
    configs: {}
    useDefaultImageRepo: true
    replicas: ""
    adminRoute: "default"
  comp:
    name: comp
    class: comp
    image: comp
    apiPort: ""
    adminPort: 8111
    eventsPort: ""
    workDir: /opt/chipster/comp
    password: ""
    configs: {}
    useDefaultImageRepo: true
    replicas: ""
    # disabled until the comp image is updated
    adminRoute: "disable"
  singleShotComp:
    name: single-shot-comp
    apiPort: ""
    adminPort: ""
    password: ""
    configs: {}
  backup:
    name: backup
    class: fi.csc.chipster.backup.Backup
    image: chipster-web-server
    apiPort: ""
    adminPort: 8115
    eventsPort: ""
    workDir: /opt/chipster
    password: ""
    configs: {}
    useDefaultImageRepo: true
    replicas: ""
    adminRoute: "default"
  jobHistory:
    name: job-history
    class: fi.csc.chipster.jobhistory.JobHistoryService
    image: chipster-web-server
    apiPort: ""
    adminPort: 8114
    eventsPort: ""
    workDir: /opt/chipster
    password: ""
    configs:
    # db-fallback disables the use of an embedded H2 database if connection to Postgres fails
    db-fallback-job-history: false
    useDefaultImageRepo: true
    replicas: ""
    adminRoute: "default"

deploymentDefault:
  replicas: 1
  adminRoute: "enable"

# databases is a section for Chipster scripts to know which databases exist
# passwordKey is the YAML path where generate-passwords.bash will store the password
# we can't store the password here, because Helm doesn't seem to have a way to rename the variable that is used in the postgresql subchart
# names with dashes have to be quoted to work in jq
databases:
  auth:
    passwordKey: "\"auth-postgresql\".postgresqlPassword"
    enabled: true
  sessionDb:
    passwordKey: "\"session-db-postgresql\".postgresqlPassword"
    enabled: true
  jobHistory:
    passwordKey: "\"job-history-postgresql\".postgresqlPassword"
    enabled: true

# generate-passwords.bash will generate all users.*.password fields
users:
  chipster:
    password: ""
  admin:
    password: ""
  example_session_owner:
    password: ""
  support_session_owner:
    password: ""

# generate-passwords.bash will generate all tokens.*.privateKey fields
tokens:
  auth:
    privateKey:
  sessionDb:
    privateKey:

# Configure depenency subcharts

# the key is the dependency alias in Chart.yaml
# aliases use dashes by convention because they are used as Kubernetes names, but then we have to use the index function to access these values in templates
auth-postgresql:
  # postgresqlDatabase is the name of the database
  postgresqlDatabase: auth_db
  # postgresqlPassword is the database password, see the comment of "databases" section 
  postgresqlPassword: ""  

session-db-postgresql:
  postgresqlDatabase: session_db_db
  postgresqlPassword: ""

job-history-postgresql:
  postgresqlDatabase: job_history_db
  postgresqlPassword: ""

# image is a section for defining how to get the images
image:
  # pullPolicy defines how to pull images from public repositories
  pullPolicy: IfNotPresent
  # localPullPolicy defines how to pull our own Chipster images
  localPullPolicy: IfNotPresent
  #localPullPolicy: Never
  chipsterImageRepo: docker-registry.rahti.csc.fi/chipster-images/

# securityContext sets the access rights of the container user
securityContext: 
  runAsNonRoot: true
  runAsUser: 1000

# capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true

# podSecurityContext allows you set fsGroup: 0, if the file permissions prevent containers to modify volumes
podSecurityContext: {}

# host is the DNS name or IP address of the K3s host. The name or address must be accessible from the users' network. For OIDC and TLS (Let's Encrypt) this must be a DNS name.
host: ""

# toolsBin is a section for settings related to the tools-bin package
toolsBin:
  # version is the tools-bin package version
  version: ""
  # volumeSize is the size of the tools-bin volume
  volumeSize: 500Gi
  # hostPath where from the tools-bin is mounted. By default it's mounted from the PVC.
  hostPath: ""
  # readOnly defines whether the tools-bin is read-only or read-write mounted to containers
  readOnly: true

tools:
  # hostPath where from tool scripts are mounted . By default the tools scripts from the image are used.
  hostPath: ""
  # manualHostPath where from manual pages are mounted . By default manual pages from the image are used.
  manualHostPath: ""


html:
  # hostPath where from the html pages are mounted. By default html pages from the image are used.
  hostPath: ""

tls:
  # env decides which Let's Encrypt environment to use. Set to "staging" to use the staging, "prod" to use the production, or "" to disable TLS.
  env: ""
  # email is the address where Let's Encrypt sends expiration notifications, when the automatic certificate renewal fails.
  email: ""

# ingress is sectino for the optional https configuration
ingress:
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local


# resources are not used in the templates yet. We would need separate definitions for different kind of services
resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi
